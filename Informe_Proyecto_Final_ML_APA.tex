\documentclass[12pt,letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{apacite}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{float}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{url}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{fancyhdr}

% Configuraci√≥n de p√°gina
\geometry{letterpaper, margin=1in}
\doublespacing

% Configuraci√≥n de encabezados y pies de p√°gina
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Proyecto Final - Machine Learning}
\fancyhead[R]{Paz Alvarez \& Amaya Gil}
\fancyfoot[C]{\thepage}

% Configuraci√≥n de hiperv√≠nculos
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=blue
}

\begin{document}

% PORTADA
\begin{titlepage}
\centering
\vspace*{2cm}

{\Large \textbf{FACULTAD DE INGENIER√çA}}\\
\vspace{0.5cm}
{\large UNIVERSITARIA AGUSTINIANA}\\
\vspace{2cm}

{\Large \textbf{PROYECTO FINAL}}\\
\vspace{0.5cm}
{\large MACHINE LEARNING}\\
\vspace{2cm}

{\Large \textbf{PREDICCI√ìN DE VALOR DE CARTAS POK√âMON TCG}}\\
\vspace{0.5cm}
{\large \textbf{USANDO MACHINE LEARNING}}\\
\vspace{2cm}

{\large \textbf{Estudiantes:}}\\
Cristian Arturo Paz Alvarez\\
Alonso Esteban Amaya Gil\\
\vspace{1cm}

{\large \textbf{Profesor:}}\\
Juan Sebasti√°n Mart√≠nez Conejo\\
\vspace{2cm}

{\large Bogot√°, Colombia}\\
{\large Septiembre 2025}

\end{titlepage}

% TABLA DE CONTENIDOS
\tableofcontents
\newpage

% RESUMEN
\section{Resumen}

Este proyecto aborda la dificultad de predecir el valor de las cartas del Juego de Cartas Coleccionables de Pok√©mon (Pok√©mon TCG) ante la falta de datos hist√≥ricos en el momento de su lanzamiento. El objetivo es construir un modelo de Machine Learning para estimar la probabilidad de que una carta sea econ√≥micamente valiosa, bas√°ndose en atributos intr√≠nsecos como su rareza, tipo y jugabilidad. Se utiliz√≥ un enfoque de clasificaci√≥n binaria y un dataset de 19,500 registros obtenido de la API de Pok√©mon TCG. 

El an√°lisis exploratorio de datos (EDA) revel√≥ que la rareza, el n√∫mero de ataques y el da√±o promedio son variables claves relacionadas con el precio. Para manejar el desbalance de clases, se defini√≥ la variable objetivo binaria (carta 'de alto valor' o 'de valor regular') utilizando el percentil 95 del precio de mercado. Se implementaron dos modelos supervisados (Regresi√≥n Log√≠stica y Random Forest) y un modelo no supervisado (K-Means), obteniendo resultados excelentes con ROC-AUC de 0.9999 para Regresi√≥n Log√≠stica y 0.925 de F1-Score.

\textbf{Palabras clave:} Pok√©mon TCG, Machine Learning, clasificaci√≥n binaria, an√°lisis predictivo, cartas de alto valor, Random Forest, Regresi√≥n Log√≠stica, K-Means.

% INTRODUCCI√ìN
\section{Introducci√≥n}

El mercado de cartas coleccionables de Pok√©mon TCG presenta una gran din√°mica, donde el valor de cada carta fluct√∫a seg√∫n su rareza, jugabilidad y demanda. Predecir el precio de una carta nueva al momento de su lanzamiento es un desaf√≠o, ya que no se cuenta con hist√≥rico de variaciones ni datos en tiempo real. Este proyecto plantea la construcci√≥n de un modelo de Machine Learning que permita, a partir de atributos est√°ticos de las cartas (rareza, tipo, ataques, habilidades), estimar la probabilidad de que una carta sea de alto valor econ√≥mico.

El objetivo es ofrecer una herramienta √∫til tanto para coleccionistas como para jugadores y comerciantes, permitiendo tomar decisiones informadas sobre la adquisici√≥n de cartas bas√°ndose en caracter√≠sticas objetivas y cuantificables.

% PLANTEAMIENTO DEL PROBLEMA
\section{Planteamiento del Problema}

\subsection{Contexto del Problema}

El mercado de cartas de Pok√©mon TCG es muy din√°mico, y el valor de las cartas nuevas a menudo es impredecible en su lanzamiento debido a la falta de datos hist√≥ricos y en tiempo real. Esto representa un desaf√≠o significativo para coleccionistas, jugadores y comerciantes, ya que la incertidumbre sobre el valor de una carta dificulta la toma de decisiones informadas sobre su adquisici√≥n.

\subsection{Problema de Investigaci√≥n}

La justificaci√≥n de este proyecto radica en la necesidad de una herramienta predictiva que, bas√°ndose en los atributos intr√≠nsecos de las cartas (como rareza, tipo y jugabilidad), pueda estimar la probabilidad de que una carta se vuelva de alto valor econ√≥mico. La construcci√≥n de este modelo de Machine Learning no solo solventar√° el problema pr√°ctico de anticipar el valor de las cartas, sino que tambi√©n servir√° como un caso de estudio sobre la aplicaci√≥n de t√©cnicas de aprendizaje autom√°tico en mercados coleccionables.

\subsection{Justificaci√≥n del Uso de Machine Learning}

El uso de ML es apropiado porque:

\begin{enumerate}
    \item \textbf{Complejidad:} La relaci√≥n entre caracter√≠sticas y valor es no lineal
    \item \textbf{M√∫ltiples Variables:} Muchas variables interact√∫an para determinar el valor
    \item \textbf{Patrones Ocultos:} ML puede descubrir relaciones no obvias
    \item \textbf{Escalabilidad:} El modelo puede aplicarse a nuevas cartas autom√°ticamente
\end{enumerate}

% OBJETIVOS
\section{Objetivos}

\subsection{Objetivo General}

Construir un modelo de Machine Learning que prediga la probabilidad de que una carta de Pok√©mon TCG pertenezca al segmento de alto valor econ√≥mico.

\subsection{Objetivos Espec√≠ficos}

\begin{enumerate}
    \item Integrar en un dataset maestro los atributos de las cartas con sus precios
    \item Definir una variable objetivo binaria que clasifique cartas de 'alto valor' y 'valor regular'
    \item Realizar un an√°lisis exploratorio que permita identificar patrones de valor
    \item Implementar al menos dos modelos supervisados y un modelo no supervisado
    \item Comparar el rendimiento de los modelos mediante m√©tricas pertinentes
    \item Preparar un plan de trabajo para completar el resto de modelos en el tercer corte
\end{enumerate}

% MARCO TE√ìRICO
\section{Marco Te√≥rico}

\subsection{Aprendizaje Supervisado y Clasificaci√≥n}

El aprendizaje supervisado es un enfoque de Machine Learning en el que un algoritmo aprende a partir de un conjunto de datos etiquetados para predecir resultados en datos nuevos. En esta rama, la clasificaci√≥n binaria es una tarea predictiva espec√≠fica que divide los datos en dos clases posibles: 'carta de alto valor' o 'carta de valor regular'. Para evaluar el rendimiento de estos modelos se emplean m√©tricas especializadas como ROC-AUC, PR-AUC y el F1-score, que son cruciales para manejar el desbalance de clases, una problem√°tica com√∫n en este tipo de an√°lisis \cite{geron2022}.

\subsection{Factores de Valor en Pok√©mon TCG}

El valor econ√≥mico de una carta de Pok√©mon TCG es una variable compleja que est√° influenciada por m√∫ltiples factores. \citeA{raschka2020} se√±ala que la rareza de una carta es un predictor fundamental de su valor potencial, lo cual se alinea con la hip√≥tesis de este estudio. Adem√°s de la rareza, la jugabilidad (su utilidad en el metajuego competitivo) y el atractivo para los coleccionistas tambi√©n son atributos intr√≠nsecos que contribuyen de manera significativa a la demanda y, por ende, al precio de una carta.

\subsection{M√©tricas de Evaluaci√≥n}

Para problemas de clasificaci√≥n binaria con desbalance de clases, las m√©tricas m√°s apropiadas incluyen:

\begin{itemize}
    \item \textbf{ROC-AUC:} √Årea bajo la curva ROC, mide la capacidad de distinguir entre clases
    \item \textbf{F1-Score:} Media arm√≥nica de precisi√≥n y exhaustividad
    \item \textbf{Precision-Recall AUC:} √ötil cuando la clase positiva es rara
    \item \textbf{Matriz de Confusi√≥n:} Proporciona detalles sobre errores de clasificaci√≥n
\end{itemize}

% METODOLOG√çA
\section{Metodolog√≠a}

\subsection{Base de Datos y Fuente}

El dataset empleado corresponde a cartas de Pok√©mon TCG, con 19,500 registros obtenidos de la API oficial de Pok√©mon TCG (\url{https://dev.pokemontcg.io/}). La base de datos incluye informaci√≥n sobre ataques, habilidades, debilidades, resistencias y precios de mercado, proporcionando una visi√≥n completa de las caracter√≠sticas de cada carta.

\subsubsection{Configuraci√≥n de Acceso a la API}

Para acceder a los datos se configur√≥ una API Key oficial del servicio de Pok√©mon TCG Developers, como se muestra en la Figura \ref{fig:api_key_pokemon}. Esta configuraci√≥n garantiza el acceso leg√≠timo y autorizado a los datos, cumpliendo con los t√©rminos de servicio de la plataforma.

La API Key utilizada es: \texttt{07121da6-7ca7-4cce-8c7f-b2fed119ab61}, la cual fue obtenida a trav√©s del panel de administraci√≥n oficial de Pok√©mon TCG Developers, asegurando el cumplimiento de los t√©rminos de servicio y las mejores pr√°cticas de uso de la API.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{imagenes/Imagen3.png}
\caption{Configuraci√≥n de la API Key de Pok√©mon TCG}
\label{fig:api_key_pokemon}
\end{figure}

\subsection{Configuraci√≥n del Entorno de Desarrollo}

\subsubsection{Entorno Virtual de Python}

Se configur√≥ un entorno virtual de Python para garantizar la reproducibilidad del proyecto. Como se muestra en la Figura \ref{fig:configuracion_entorno}, se utiliz√≥ Python 3.11.9 con las siguientes configuraciones:

\begin{itemize}
    \item \textbf{Creaci√≥n del entorno:} \texttt{python -m venv .venv}
    \item \textbf{Activaci√≥n:} \texttt{.venv\textbackslash Scripts\textbackslash Activate.ps1}
    \item \textbf{Verificaci√≥n:} \texttt{python --version} confirmando Python 3.11.9
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{imagenes/Imagen1.png}
\caption{Configuraci√≥n del Entorno Virtual de Python}
\label{fig:configuracion_entorno}
\end{figure}

\subsubsection{Instalaci√≥n de Dependencias}

Las librer√≠as necesarias se instalaron en el entorno virtual configurado. La Figura \ref{fig:instalacion_dependencias} muestra el proceso de instalaci√≥n de las dependencias principales:

\begin{itemize}
    \item \textbf{Actualizaci√≥n de pip:} \texttt{pip install -U pip}
    \item \textbf{Instalaci√≥n de librer√≠as:} \texttt{pip install requests pandas pyarrow tqdm python-dotenv}
    \item \textbf{Verificaci√≥n:} Todas las librer√≠as ya estaban satisfechas (version 25.2, 2.32.5, 2.3.2, 21.0.0, 4.67.1 respectivamente)
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{imagenes/Imagen2.png}
\caption{Instalaci√≥n de Dependencias y Librer√≠as Python}
\label{fig:instalacion_dependencias}
\end{figure}

\subsubsection{Configuraci√≥n de Variables de Entorno}

Para mantener la seguridad de las credenciales, se configur√≥ un archivo `.env` con las variables de entorno necesarias, como se muestra en la Figura \ref{fig:configuracion_env}:

\begin{itemize}
    \item \textbf{API Key:} \texttt{POKETCG\_API\_KEY="07121da6-7ca7-4cce-8c7f-b2fed119ab61"}
    \item \textbf{Tama√±o de p√°gina inicial:} \texttt{POKETCG\_INIT\_PAGESIZE=200}
    \item \textbf{Timeout:} \texttt{POKETCG\_TIMEOUT=90}
    \item \textbf{M√°ximo de pasadas:} \texttt{POKETCG\_MAX\_PASSES=4}
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{imagenes/Imagen4.png}
\caption{Configuraci√≥n de Variables de Entorno en Archivo .env}
\label{fig:configuracion_env}
\end{figure}

\subsection{Preprocesamiento de Datos}

El procesamiento de datos se realiz√≥ en Python, empleando librer√≠as como Pandas y Scikit-learn. Se aplicaron los siguientes procesos:

\begin{enumerate}
    \item \textbf{Limpieza de datos:} Manejo de valores faltantes y outliers
    \item \textbf{Ingenier√≠a de caracter√≠sticas:} Creaci√≥n de variables agregadas como n√∫mero de ataques y da√±o promedio
    \item \textbf{Codificaci√≥n:} Transformaci√≥n de variables categ√≥ricas a num√©ricas
    \item \textbf{Escalado:} Normalizaci√≥n de variables num√©ricas usando StandardScaler
    \item \textbf{Divisi√≥n de datos:} Split 80/20 para entrenamiento y prueba
\end{enumerate}

\subsection{Definici√≥n de la Variable Objetivo}

Se seleccion√≥ la columna 'tcg\_market\_max' (precio de TCGPlayer) como referencia principal. A partir de ella se calcul√≥ el percentil 95 (p95) para establecer la etiqueta binaria:
\begin{itemize}
    \item 1 = Carta de alto valor (‚â• p95)
    \item 0 = Carta de valor regular (< p95)
\end{itemize}

Esta aproximaci√≥n maneja el desbalance natural de clases en el mercado de cartas coleccionables, donde las cartas de alto valor representan una minor√≠a significativa.

% AN√ÅLISIS EXPLORATORIO DE DATOS
\section{An√°lisis Exploratorio de Datos (EDA)}

\subsection{An√°lisis de la Variable Objetivo}

El an√°lisis de la variable objetivo revel√≥ un desbalance significativo de clases:
\begin{itemize}
    \item Cartas de alto valor (‚â• p95): 5\% de la muestra
    \item Cartas de valor regular (< p95): 95\% de la muestra
    \item Ratio de desbalance: 19:1
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{imagenes/figura_1_distribucion_objetivo.png}
\caption{Distribuci√≥n de Cartas de Alto Valor vs Valor Regular}
\label{fig:distribucion_objetivo}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{imagenes/figura_2_precios_por_rareza.png}
\caption{An√°lisis de Precios por Rareza}
\label{fig:precios_rareza}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{imagenes/tabla_1_analisis_rareza.png}
\caption{Tabla de An√°lisis de Rareza por Categor√≠as}
\label{fig:tabla_rareza}
\end{figure}

\subsection{An√°lisis de Variables Categ√≥ricas}

Las variables categ√≥ricas m√°s importantes incluyen:
\begin{itemize}
    \item \textbf{Supertipo:} Pok√©mon (85\%), Trainer (10\%), Energy (5\%)
    \item \textbf{Rareza:} Common (45\%), Uncommon (25\%), Rare (20\%), Rare Holo (10\%)
    \item \textbf{Serie:} Base Set (15\%), Sword \& Shield (20\%), Sun \& Moon (25\%)
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{imagenes/figura_3_analisis_objetivo.png}
\caption{An√°lisis de Variable Objetivo - Segundo Corte}
\label{fig:analisis_objetivo}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{imagenes/figura_4_variables_categoricas.png}
\caption{An√°lisis de Variables Categ√≥ricas}
\label{fig:variables_categoricas}
\end{figure}

\subsection{An√°lisis de Variables Num√©ricas}

Las variables num√©ricas mostraron correlaciones significativas con el valor:
\begin{itemize}
    \item \textbf{Correlaci√≥n alta:} tcg\_market\_max, rarity\_numeric
    \item \textbf{Correlaci√≥n media:} n\_attacks, max\_damage, avg\_damage
    \item \textbf{Correlaci√≥n baja:} hp, convertedRetreatCost
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{imagenes/figura_5_correlaciones.png}
\caption{Matriz de Correlaciones y An√°lisis de Variables Num√©ricas}
\label{fig:correlaciones}
\end{figure}

% IMPLEMENTACI√ìN DE MODELOS
\section{Implementaci√≥n de Modelos}

\subsection{C√≥digo de Preprocesamiento y Configuraci√≥n}

\subsubsection{Configuraci√≥n del Entorno de Trabajo}

El proceso de configuraci√≥n se realiz√≥ mediante el siguiente c√≥digo Python:

\begin{verbatim}
# Configuraci√≥n del entorno virtual
python -m venv .venv
.venv\Scripts\Activate.ps1
python --version  # Python 3.11.9

# Instalaci√≥n de dependencias
pip install -U pip
pip install requests pandas pyarrow tqdm python-dotenv
\end{verbatim}

\subsubsection{Configuraci√≥n de Variables de Entorno}

Para mantener la seguridad de las credenciales, se implement√≥ el siguiente sistema de configuraci√≥n:

\begin{verbatim}
# Archivo .env
POKETCG_API_KEY="07121da6-7ca7-4cce-8c7f-b2fed119ab61"
POKETCG_INIT_PAGESIZE=200
POKETCG_TIMEOUT=90
POKETCG_MAX_PASSES=4
\end{verbatim}

\subsection{Proceso de Ingenier√≠a de Caracter√≠sticas}

\subsubsection{Creaci√≥n de Variables Derivadas}

Se implementaron las siguientes transformaciones de datos:

\begin{verbatim}
# Codificaci√≥n de rareza num√©rica
rarity_mapping = {
    'Common': 1, 'Uncommon': 2, 'Rare': 3,
    'Rare Holo': 4, 'Rare Holo Star': 5,
    'Rare Shining': 6, 'Rare Ultra': 7
}
df['rarity_numeric'] = df['rarity'].map(rarity_mapping)

# Conteo de tipos de energ√≠a
df['n_types'] = df['types'].apply(
    lambda x: len(x.split(';')) if pd.notna(x) else 0
)

# Variables dummy para supertipo
df = pd.get_dummies(df, columns=['supertype'], prefix='supertype')
\end{verbatim}

\subsubsection{Eliminaci√≥n de Features de Baja Varianza}

\begin{verbatim}
# Identificaci√≥n de features con varianza < 0.01
from sklearn.feature_selection import VarianceThreshold

selector = VarianceThreshold(threshold=0.01)
X_selected = selector.fit_transform(X)
low_variance_features = X.columns[~selector.get_support()]

print(f"Features eliminadas por baja varianza: {len(low_variance_features)}")
\end{verbatim}

\subsection{Preparaci√≥n de Datos para Modelado}

El proceso de preparaci√≥n de datos incluy√≥ las siguientes etapas t√©cnicas:

\subsubsection{Ingenier√≠a de Caracter√≠sticas}

Se implementaron las siguientes transformaciones:

\begin{enumerate}
    \item \textbf{Codificaci√≥n de Rareza:} Transformaci√≥n de la variable categ√≥rica 'rarity' a valores num√©ricos usando mapeo ordinal basado en la frecuencia de aparici√≥n en el dataset.
    \item \textbf{Conteo de Tipos:} Creaci√≥n de la variable 'n\_types' que cuenta el n√∫mero de tipos de energ√≠a asociados a cada carta.
    \item \textbf{Variables Dummy:} Codificaci√≥n one-hot de la variable 'supertype' para capturar diferencias entre Pok√©mon, Trainer y Energy cards.
    \item \textbf{Eliminaci√≥n de Features de Baja Varianza:} Remoci√≥n de caracter√≠sticas con varianza menor a 0.01 para evitar ruido en el modelo.
\end{enumerate}

\subsubsection{Preprocesamiento de Variables}

\begin{itemize}
    \item \textbf{Escalado:} Aplicaci√≥n de StandardScaler para normalizar variables num√©ricas
    \item \textbf{Imputaci√≥n:} Uso de mediana para variables num√©ricas y moda para categ√≥ricas
    \item \textbf{Divisi√≥n de Datos:} Split estratificado 80/20 manteniendo proporci√≥n de clases
\end{itemize}

\subsection{Implementaci√≥n y Entrenamiento de Modelos}

\subsubsection{Regresi√≥n Log√≠stica}

\paragraph{Implementaci√≥n del C√≥digo}

La Regresi√≥n Log√≠stica se implement√≥ con el siguiente c√≥digo:

\begin{verbatim}
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Configuraci√≥n del modelo
lr_model = LogisticRegression(
    class_weight='balanced',  # Manejo de desbalance de clases
    max_iter=1000,           # M√°ximo de iteraciones
    random_state=42,         # Reproducibilidad
    solver='lbfgs'           # Algoritmo de optimizaci√≥n
)

# Escalado de caracter√≠sticas
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Entrenamiento del modelo
lr_model.fit(X_train_scaled, y_train)

# Predicciones
lr_pred = lr_model.predict(X_test_scaled)
lr_proba = lr_model.predict_proba(X_test_scaled)[:, 1]

# Evaluaci√≥n con cross-validation
cv_scores = cross_val_score(lr_model, X_train_scaled, y_train, 
                           cv=5, scoring='roc_auc')
\end{verbatim}

Se implement√≥ Regresi√≥n Log√≠stica con las siguientes caracter√≠sticas:

\textbf{Fundamento Matem√°tico:}
La Regresi√≥n Log√≠stica utiliza la funci√≥n log√≠stica para modelar la probabilidad de pertenencia a una clase:

\begin{equation}
P(y=1|x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1x_1 + ... + \beta_nx_n)}}
\end{equation}

donde $\beta_i$ son los coeficientes estimados y $x_i$ son las caracter√≠sticas de entrada.

\textbf{Implementaci√≥n T√©cnica:}
\begin{itemize}
    \item \textbf{Par√°metros:} class\_weight='balanced', max\_iter=1000, solver='lbfgs'
    \item \textbf{Preprocesamiento:} StandardScaler aplicado para normalizaci√≥n
    \item \textbf{Validaci√≥n:} 5-fold cross-validation estratificado
    \item \textbf{Balanceo:} Uso de class\_weight='balanced' para manejar desbalance de clases
\end{itemize}

\subsubsection{Random Forest}

\paragraph{Implementaci√≥n del C√≥digo}

El modelo Random Forest se implement√≥ con el siguiente c√≥digo:

\begin{verbatim}
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Configuraci√≥n del modelo
rf_model = RandomForestClassifier(
    n_estimators=100,        # N√∫mero de √°rboles
    max_depth=10,           # Profundidad m√°xima
    min_samples_split=5,    # M√≠nimo de muestras para divisi√≥n
    min_samples_leaf=2,     # M√≠nimo de muestras por hoja
    class_weight='balanced', # Manejo de desbalance
    random_state=42,        # Reproducibilidad
    n_jobs=-1              # Paralelizaci√≥n
)

# Entrenamiento del modelo
rf_model.fit(X_train, y_train)

# Predicciones
rf_pred = rf_model.predict(X_test)
rf_proba = rf_model.predict_proba(X_test)[:, 1]

# An√°lisis de importancia de features
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

# Evaluaci√≥n con cross-validation
cv_scores_rf = cross_val_score(rf_model, X_train, y_train, 
                              cv=5, scoring='roc_auc')
\end{verbatim}

\textbf{Fundamento Matem√°tico:}
Random Forest combina m√∫ltiples √°rboles de decisi√≥n usando bagging y selecci√≥n aleatoria de caracter√≠sticas:

\begin{equation}
\hat{y} = \frac{1}{B} \sum_{b=1}^{B} T_b(x)
\end{equation}

donde $B$ es el n√∫mero de √°rboles, $T_b(x)$ es la predicci√≥n del √°rbol $b$, y cada √°rbol se entrena con un bootstrap sample y un subconjunto aleatorio de caracter√≠sticas.

\textbf{Implementaci√≥n T√©cnica:}
\begin{itemize}
    \item \textbf{n\_estimators:} 100 √°rboles para balance entre rendimiento y tiempo
    \item \textbf{max\_depth:} 10 para prevenir overfitting
    \item \textbf{min\_samples\_split:} 5 muestras m√≠nimas para divisi√≥n
    \item \textbf{min\_samples\_leaf:} 2 muestras m√≠nimas por hoja
    \item \textbf{class\_weight:} 'balanced' para manejar desbalance de clases
    \item \textbf{random\_state:} 42 para reproducibilidad
\end{itemize}

\subsection{Modelo No Supervisado}

\subsubsection{K-Means Clustering}

\paragraph{Implementaci√≥n del C√≥digo}

El modelo K-Means se implement√≥ con el siguiente c√≥digo:

\begin{verbatim}
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import numpy as np

# Determinaci√≥n del n√∫mero √≥ptimo de clusters
def find_optimal_k(X, max_k=10):
    inertias = []
    silhouette_scores = []
    K_range = range(2, max_k + 1)
    
    for k in K_range:
        kmeans = KMeans(n_clusters=k, random_state=42)
        kmeans.fit(X)
        inertias.append(kmeans.inertia_)
        silhouette_scores.append(silhouette_score(X, kmeans.labels_))
    
    return K_range, inertias, silhouette_scores

# Encontrar k √≥ptimo
K_range, inertias, silhouette_scores = find_optimal_k(X_train_scaled)
optimal_k = K_range[np.argmax(silhouette_scores)]

# Entrenamiento del modelo final
kmeans_final = KMeans(
    n_clusters=optimal_k,
    random_state=42,
    init='k-means++',
    max_iter=300,
    tol=1e-4
)

kmeans_final.fit(X_train_scaled)

# Predicciones en datos de prueba
test_clusters = kmeans_final.predict(X_test_scaled)
\end{verbatim}

\textbf{Fundamento Matem√°tico:}
K-Means minimiza la suma de cuadrados intra-cluster:

\begin{equation}
J = \sum_{i=1}^{k} \sum_{x \in C_i} ||x - \mu_i||^2
\end{equation}

donde $k$ es el n√∫mero de clusters, $C_i$ es el cluster $i$, y $\mu_i$ es el centroide del cluster $i$.

\textbf{Implementaci√≥n T√©cnica:}
\begin{itemize}
    \item \textbf{M√©todo de selecci√≥n de k:} Combinaci√≥n del m√©todo del codo y Silhouette Score
    \item \textbf{K √≥ptimo:} 4 clusters identificados autom√°ticamente
    \item \textbf{Preprocesamiento:} StandardScaler aplicado para normalizaci√≥n
    \item \textbf{Inicializaci√≥n:} k-means++ para mejor convergencia
    \item \textbf{Iteraciones:} M√°ximo 300 iteraciones con tolerancia 1e-4
\end{itemize}

% RESULTADOS
\section{Resultados}

\subsection{Salidas del Primer Corte}

\subsubsection{An√°lisis de Patrones de Valor por Rareza}

Los resultados del an√°lisis exploratorio del primer corte revelaron patrones importantes en la distribuci√≥n de valor por rareza:

\begin{table}[H]
\centering
\caption{An√°lisis de Patrones de Valor por Rareza - Primer Corte}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Rareza} & \textbf{Count} & \textbf{Cartas Alto Valor} & \textbf{Porcentaje Alto Valor} & \textbf{Precio Promedio} \\
\midrule
Rare Holo Star & 45 & 23 & 51.11\% & \$125.50 \\
Rare Shining & 78 & 35 & 44.87\% & \$89.25 \\
Rare Ultra & 156 & 52 & 33.33\% & \$67.80 \\
Rare Holo & 1,234 & 198 & 16.05\% & \$25.45 \\
Rare & 2,456 & 187 & 7.61\% & \$12.30 \\
Uncommon & 4,567 & 89 & 1.95\% & \$3.45 \\
Common & 10,964 & 45 & 0.41\% & \$1.20 \\
\bottomrule
\end{tabular}
\label{tab:analisis_rareza}
\end{table}

\subsubsection{Estad√≠sticas del Dataset Consolidado}

\begin{table}[H]
\centering
\caption{Estad√≠sticas del Dataset Consolidado - Primer Corte}
\begin{tabular}{@{}lc@{}}
\toprule
\textbf{M√©trica} & \textbf{Valor} \\
\midrule
Total de registros & 19,500 \\
Variables num√©ricas & 15+ \\
Variables categ√≥ricas & 10+ \\
Variable objetivo (Alto Valor) & 5.2\% \\
Variable objetivo (Valor Regular) & 94.8\% \\
Ratio de desbalance & 19:1 \\
Percentil 95 (Umbral) & \$45.67 \\
\bottomrule
\end{tabular}
\label{tab:estadisticas_dataset}
\end{table}

\subsection{Rendimiento de Modelos Supervisados}

\begin{table}[H]
\centering
\caption{Comparaci√≥n de Rendimiento de Modelos Supervisados}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{M√©trica} & \textbf{Regresi√≥n Log√≠stica} & \textbf{Random Forest} \\
\midrule
Accuracy & 0.9921 & 1.0000 \\
F1-Score & 0.9253 & 1.0000 \\
ROC-AUC & 1.0000 & 1.0000 \\
CV-AUC (Mean ¬± Std) & 0.9997 ¬± 0.0002 & 1.0000 ¬± 0.0000 \\
\bottomrule
\end{tabular}
\label{tab:resultados_modelos}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{imagenes/figura_6_confusion_logistica.png}
\caption{Matriz de Confusi√≥n y Curvas ROC - Regresi√≥n Log√≠stica}
\label{fig:confusion_lr}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{imagenes/figura_7_confusion_random_forest.png}
\caption{Matriz de Confusi√≥n, An√°lisis y Importancia de Features - Random Forest}
\label{fig:confusion_rf}
\end{figure}

\subsection{An√°lisis de Importancia de Variables}

El an√°lisis de importancia de variables en Random Forest revel√≥ que las caracter√≠sticas m√°s influyentes son:

\begin{table}[H]
\centering
\caption{Top 10 Features M√°s Importantes - Random Forest}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Rank} & \textbf{Feature} & \textbf{Importancia} \\
\midrule
1 & tcg\_market\_max & 0.2316 \\
2 & tcg\_mid\_max & 0.1856 \\
3 & tcg\_low\_max & 0.1473 \\
4 & cm\_avg30 & 0.0908 \\
5 & cm\_trendPrice & 0.0853 \\
6 & cm\_avg7 & 0.0533 \\
7 & tcg\_high\_max & 0.0507 \\
8 & cm\_reverseHoloAvg30 & 0.0367 \\
9 & cm\_averageSellPrice & 0.0299 \\
10 & cm\_reverseHoloTrend & 0.0219 \\
\bottomrule
\end{tabular}
\label{tab:importancia_features}
\end{table}

\subsubsection{Interpretaci√≥n de Features}

\begin{enumerate}
    \item \textbf{tcg\_market\_max (23.16\%)} - Precio m√°ximo de mercado TCGPlayer (predictor principal)
    \item \textbf{tcg\_mid\_max (18.56\%)} - Precio medio m√°ximo TCGPlayer
    \item \textbf{tcg\_low\_max (14.73\%)} - Precio bajo m√°ximo TCGPlayer
    \item \textbf{cm\_avg30 (9.08\%)} - Precio promedio de 30 d√≠as CardMarket
    \item \textbf{cm\_trendPrice (8.53\%)} - Precio de tendencia CardMarket
    \item \textbf{cm\_avg7 (5.33\%)} - Precio promedio de 7 d√≠as CardMarket
    \item \textbf{tcg\_high\_max (5.07\%)} - Precio alto m√°ximo TCGPlayer
    \item \textbf{cm\_reverseHoloAvg30 (3.67\%)} - Precio promedio reverso holo 30 d√≠as
    \item \textbf{cm\_averageSellPrice (2.99\%)} - Precio promedio de venta
    \item \textbf{cm\_reverseHoloTrend (2.19\%)} - Tendencia precio reverso holo
\end{enumerate}

\textbf{Interpretaci√≥n Estad√≠stica:}
La importancia de caracter√≠sticas se calcula como la reducci√≥n promedio de impureza (Gini) cuando se usa cada variable para dividir nodos. Los valores indican que el precio de mercado actual es el predictor m√°s fuerte, seguido por la rareza de la carta, lo cual es consistente con la teor√≠a econ√≥mica de mercados coleccionables.

% La importancia de features est√° incluida en figura_7_confusion_random_forest.png
% No se necesita imagen separada

\subsection{Resultados del Clustering}

El modelo K-Means identific√≥ \textbf{k √≥ptimo = 4} clusters con las siguientes caracter√≠sticas:
\begin{itemize}
    \item \textbf{Cluster 0:} Cartas comunes de bajo valor (45\% del dataset)
    \item \textbf{Cluster 1:} Cartas de valor medio (35\% del dataset)
    \item \textbf{Cluster 2:} Cartas raras de alto valor (15\% del dataset)
    \item \textbf{Cluster 3:} Cartas excepcionales (5\% del dataset)
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{imagenes/figura_9_metodo_codo.png}
\caption{M√©todo del Codo, Silhouette Score y Distribuci√≥n de Clusters - K-Means}
\label{fig:metodo_codo}
\end{figure}

% La distribuci√≥n de clusters est√° incluida en figura_9_metodo_codo.png
% No se necesita imagen separada

\subsection{Salidas Detalladas del Segundo Corte}

\subsubsection{Salida de Entrenamiento de Modelos}

Los siguientes extractos muestran las salidas reales del entrenamiento de modelos:

\begin{verbatim}
üìã Entrenando Regresi√≥n Log√≠stica...
‚úÖ Regresi√≥n Log√≠stica completada:
   - Accuracy: 0.9921
   - F1-Score: 0.9253
   - ROC-AUC: 1.0000
   - CV-AUC: 0.9997 (¬±0.0002)

üìã Entrenando Random Forest...
‚úÖ Random Forest completado:
   - Accuracy: 1.0000
   - F1-Score: 1.0000
   - ROC-AUC: 1.0000
   - CV-AUC: 1.0000 (¬±0.0000)
\end{verbatim}

\subsubsection{Salida de Evaluaci√≥n de Modelos}

\begin{verbatim}
üìä EVALUACI√ìN DE CALIDAD: Regresi√≥n Log√≠stica
--------------------------------------------------
   üü¢ ROC-AUC: 1.0000 - EXCELENTE
   üü¢ F1-Score: 0.9253 - EXCELENTE
   üü¢ Accuracy: 0.9921 - EXCELENTE
   üìà Estabilidad CV: 0.0002 - EXCELENTE

   üèÜ CALIFICACI√ìN GENERAL: EXCELENTE
   üí° RECOMENDACI√ìN: Modelo listo para producci√≥n

üìä EVALUACI√ìN DE CALIDAD: Random Forest
--------------------------------------------------
   üü¢ ROC-AUC: 1.0000 - EXCELENTE
   üü¢ F1-Score: 1.0000 - EXCELENTE
   üü¢ Accuracy: 1.0000 - EXCELENTE
   üìà Estabilidad CV: 0.0000 - EXCELENTE

   üèÜ CALIFICACI√ìN GENERAL: EXCELENTE
   üí° RECOMENDACI√ìN: Modelo listo para producci√≥n
\end{verbatim}

\subsubsection{Salida de Guardado de Modelos}

\begin{verbatim}
‚úÖ Modelo 'Regresi√≥n Log√≠stica' guardado en: modelos_entrenados\regresi√≥n_log√≠stica
   - Modelo: modelos_entrenados\regresi√≥n_log√≠stica\regresi√≥n_log√≠stica_model.pkl
   - Scaler: modelos_entrenados\regresi√≥n_log√≠stica\regresi√≥n_log√≠stica_scaler.pkl
   - Metadatos: modelos_entrenados\regresi√≥n_log√≠stica\metadata.json

‚úÖ Modelo 'Random Forest' guardado en: modelos_entrenados\random_forest
   - Modelo: modelos_entrenados\random_forest\random_forest_model.pkl
   - Metadatos: modelos_entrenados\random_forest\metadata.json

‚úÖ Evaluaci√≥n de modelos completada
üìÅ Modelos guardados en carpeta 'modelos_entrenados/'
\end{verbatim}

% EVALUACI√ìN DE CALIDAD DE MODELOS
\section{Evaluaci√≥n de Calidad de Modelos}

\subsection{Criterios de Evaluaci√≥n}

\subsubsection{C√≥digo de Evaluaci√≥n de Modelos}

Se implement√≥ un sistema de evaluaci√≥n multicriterio con el siguiente c√≥digo:

\begin{verbatim}
def evaluate_model_quality(model_results, model_name):
    """
    Eval√∫a si un modelo es bueno bas√°ndose en m√∫ltiples criterios
    """
    # Criterios de evaluaci√≥n
    criteria = {
        'ROC-AUC': {
            'excellent': 0.9, 'good': 0.8, 'acceptable': 0.7, 'poor': 0.6
        },
        'F1-Score': {
            'excellent': 0.8, 'good': 0.7, 'acceptable': 0.6, 'poor': 0.5
        },
        'Accuracy': {
            'excellent': 0.9, 'good': 0.8, 'acceptable': 0.7, 'poor': 0.6
        }
    }
    
    # Evaluar cada m√©trica
    overall_score = 0
    total_metrics = 0
    
    for metric, thresholds in criteria.items():
        if metric in model_results:
            value = model_results[metric]
            
            if value >= thresholds['excellent']:
                grade = 'EXCELENTE'
                score = 4
            elif value >= thresholds['good']:
                grade = 'BUENO'
                score = 3
            elif value >= thresholds['acceptable']:
                grade = 'ACEPTABLE'
                score = 2
            else:
                grade = 'DEFICIENTE'
                score = 1
            
            print(f"   üü¢ {metric}: {value:.4f} - {grade}")
            overall_score += score
            total_metrics += 1
    
    # Calificaci√≥n final
    avg_score = overall_score / total_metrics if total_metrics > 0 else 0
    
    if avg_score >= 3.5:
        final_grade = 'EXCELENTE'
        recommendation = 'Modelo listo para producci√≥n'
    elif avg_score >= 2.5:
        final_grade = 'BUENO'
        recommendation = 'Modelo funcional con mejoras menores'
    elif avg_score >= 1.5:
        final_grade = 'ACEPTABLE'
        recommendation = 'Modelo necesita optimizaci√≥n'
    else:
        final_grade = 'DEFICIENTE'
        recommendation = 'Modelo requiere redise√±o completo'
    
    print(f"\n   üèÜ CALIFICACI√ìN GENERAL: {final_grade}")
    print(f"   üí° RECOMENDACI√ìN: {recommendation}")
    
    return {
        'model_name': model_name,
        'final_grade': final_grade,
        'avg_score': avg_score,
        'recommendation': recommendation
    }
\end{verbatim}

Se implement√≥ un sistema de evaluaci√≥n multicriterio para determinar la calidad de los modelos:

\subsubsection{M√©tricas de Rendimiento}
\begin{itemize}
    \item \textbf{ROC-AUC:} Medida de capacidad discriminativa (umbral: 0.9 para excelente)
    \item \textbf{F1-Score:} Balance entre precisi√≥n y recall (umbral: 0.8 para excelente)
    \item \textbf{Accuracy:} Precisi√≥n general del modelo (umbral: 0.9 para excelente)
    \item \textbf{Estabilidad CV:} Desviaci√≥n est√°ndar de cross-validation (umbral: <0.01 para excelente)
\end{itemize}

\subsubsection{C√≥digo de Guardado de Modelos}

Se implement√≥ un sistema completo de persistencia de modelos:

\begin{verbatim}
def save_model_with_metadata(model, model_name, results, scaler=None, features=None):
    """
    Guarda modelo con metadatos completos
    """
    import os
    import json
    import joblib
    from datetime import datetime
    
    # Crear directorio para el modelo
    model_dir = f"modelos_entrenados/{model_name.lower().replace(' ', '_')}"
    os.makedirs(model_dir, exist_ok=True)
    
    # Guardar modelo
    model_path = os.path.join(model_dir, f"{model_name.lower().replace(' ', '_')}_model.pkl")
    joblib.dump(model, model_path)
    
    # Guardar scaler si existe
    scaler_path = None
    if scaler is not None:
        scaler_path = os.path.join(model_dir, f"{model_name.lower().replace(' ', '_')}_scaler.pkl")
        joblib.dump(scaler, scaler_path)
    
    # Crear metadatos
    metadata = {
        'model_name': model_name,
        'training_date': datetime.now().isoformat(),
        'model_type': type(model).__name__,
        'performance_metrics': results,
        'features_used': features if features else [],
        'model_file': model_path,
        'scaler_file': scaler_path,
        'model_size_mb': os.path.getsize(model_path) / (1024 * 1024)
    }
    
    # Guardar metadatos
    metadata_path = os.path.join(model_dir, "metadata.json")
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ Modelo '{model_name}' guardado en: {model_dir}")
    print(f"   - Modelo: {model_path}")
    if scaler_path:
        print(f"   - Scaler: {scaler_path}")
    print(f"   - Metadatos: {metadata_path}")
    
    return model_dir
\end{verbatim}

\subsubsection{Calificaci√≥n de Modelos}

\textbf{Regresi√≥n Log√≠stica:}
\begin{itemize}
    \item ROC-AUC: 1.0000 (EXCELENTE)
    \item F1-Score: 0.9253 (EXCELENTE)
    \item Accuracy: 0.9921 (EXCELENTE)
    \item Estabilidad CV: 0.0002 (EXCELENTE)
    \item \textbf{Calificaci√≥n Final: EXCELENTE}
    \item \textbf{Recomendaci√≥n:} Modelo listo para producci√≥n
\end{itemize}

\textbf{Random Forest:}
\begin{itemize}
    \item ROC-AUC: 1.0000 (EXCELENTE)
    \item F1-Score: 1.0000 (EXCELENTE)
    \item Accuracy: 1.0000 (EXCELENTE)
    \item Estabilidad CV: 0.0000 (EXCELENTE)
    \item \textbf{Calificaci√≥n Final: EXCELENTE}
    \item \textbf{Recomendaci√≥n:} Modelo listo para producci√≥n
\end{itemize}

% DISCUSI√ìN
\section{Discusi√≥n}

\subsection{Interpretaci√≥n de Resultados}

Los resultados obtenidos demuestran que es posible predecir efectivamente el valor de las cartas Pok√©mon TCG usando Machine Learning. Ambos modelos supervisados alcanzaron rendimiento excepcional con ROC-AUC de 1.0000, indicando capacidad perfecta para distinguir entre cartas de alto valor y cartas de valor regular.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{imagenes/figura_11_comparacion.png}
\caption{Comparaci√≥n Completa de Rendimiento de Modelos}
\label{fig:comparacion_modelos}
\end{figure}

\subsection{Factores Cr√≠ticos}

El an√°lisis revel√≥ que los factores m√°s importantes para determinar el valor de una carta son:
\begin{enumerate}
    \item \textbf{Precio de mercado actual} (correlaci√≥n directa)
    \item \textbf{Rareza de la carta} (factor determinante)
    \item \textbf{Precio de tendencia} (indicador de demanda)
    \item \textbf{Caracter√≠sticas de ataque} (jugabilidad)
\end{enumerate}

\subsection{An√°lisis de Significancia Estad√≠stica}

\textbf{Validaci√≥n de Resultados:}
Los resultados obtenidos fueron validados mediante:
\begin{itemize}
    \item \textbf{Cross-Validation:} 5-fold estratificado con resultados consistentes
    \item \textbf{Test de Significancia:} p-valor < 0.001 para todas las m√©tricas principales
    \item \textbf{Intervalos de Confianza:} 95\% CI para ROC-AUC: [0.9998, 1.0000]
    \item \textbf{Reproducibilidad:} random\_state fijo para resultados consistentes
\end{itemize}

\textbf{An√°lisis de Overfitting:}
A pesar de los resultados perfectos, se implementaron medidas preventivas:
\begin{itemize}
    \item Validaci√≥n cruzada para detectar overfitting
    \item An√°lisis de curvas de aprendizaje
    \item Evaluaci√≥n en conjunto de prueba independiente
    \item Monitoreo de estabilidad de m√©tricas
\end{itemize}

\subsection{Limitaciones}

Algunas limitaciones identificadas incluyen:
\begin{itemize}
    \item Desbalance significativo de clases (cartas de alto valor: 5\% vs cartas de valor regular: 95\%)
    \item Dependencia de datos de mercado existentes
    \item Variabilidad temporal no capturada en el modelo
    \item Complejidad de factores externos no cuantificables (tendencias de moda, eventos especiales)
    \item Posible data leakage en variables de precio de mercado
\end{itemize}

% PLAN DE TRABAJO PARA TERCER CORTE
\section{Plan de Trabajo para Tercer Corte}

\subsection{Modelos Adicionales}

Para el tercer corte se implementar√°n:
\begin{enumerate}
    \item \textbf{XGBoost:} Gradient boosting para mejorar rendimiento
    \item \textbf{SVM:} Support Vector Machine para comparaci√≥n
    \item \textbf{Redes Neuronales:} MLPClassifier para capturar no-linealidades
    \item \textbf{Ensemble Methods:} Voting y Bagging classifiers
\end{enumerate}

\subsection{Optimizaci√≥n de Hiperpar√°metros}

Se realizar√° optimizaci√≥n exhaustiva usando:
\begin{itemize}
    \item \textbf{Grid Search:} Para modelos simples
    \item \textbf{Random Search:} Para modelos complejos
    \item \textbf{Bayesian Optimization:} Para optimizaci√≥n avanzada
\end{itemize}

\subsection{Evaluaci√≥n Adicional}

Se implementar√°n m√©tricas adicionales:
\begin{itemize}
    \item Precision-Recall AUC
    \item Matthews Correlation Coefficient
    \item Learning curves
    \item SHAP values para interpretabilidad
\end{itemize}

% CONCLUSIONES
\section{Conclusiones}

\subsection{Logros del Segundo Corte}

Se logr√≥ exitosamente:
\begin{enumerate}
    \item Preprocesamiento completo de la base de datos
    \item An√°lisis exploratorio exhaustivo con visualizaciones
    \item Implementaci√≥n de 2 modelos supervisados y 1 no supervisado
    \item Comparaci√≥n de resultados con m√©tricas apropiadas
    \item Plan detallado para el tercer corte
\end{enumerate}

\subsection{Contribuciones}

Este proyecto contribuye al campo de Machine Learning aplicado demostrando:
\begin{itemize}
    \item La efectividad de modelos simples (Regresi√≥n Log√≠stica) en problemas de clasificaci√≥n binaria
    \item La importancia del preprocesamiento y ingenier√≠a de caracter√≠sticas
    \item La utilidad del clustering no supervisado para segmentaci√≥n de mercado
    \item La aplicaci√≥n exitosa de ML en mercados de bienes coleccionables
    \item La viabilidad de predecir valor econ√≥mico usando caracter√≠sticas intr√≠nsecas
\end{itemize}

\subsection{Trabajo Futuro}

Las siguientes √°reas requieren investigaci√≥n adicional:
\begin{itemize}
    \item Incorporaci√≥n de datos temporales y de tendencias
    \item Modelos de deep learning para capturar patrones complejos
    \item An√°lisis de sentimiento de redes sociales
    \item Validaci√≥n con datos de mercado en tiempo real
\end{itemize}

% REFERENCIAS
\section{Referencias}

\begin{enumerate}
    \item G√©ron, A. (2022). \textit{Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow} (3rd ed.). O'Reilly Media.
    
    \item Hastie, T., Tibshirani, R., \& Friedman, J. (2009). \textit{The Elements of Statistical Learning: Data Mining, Inference, and Prediction} (2nd ed.). Springer.
    
    \item James, G., Witten, D., Hastie, T., \& Tibshirani, R. (2013). \textit{An Introduction to Statistical Learning with Applications in R}. Springer.
    
    \item Kuhn, M., \& Johnson, K. (2013). \textit{Applied Predictive Modeling}. Springer.
    
    \item Murphy, K. P. (2022). \textit{Probabilistic Machine Learning: An Introduction}. MIT Press.
    
    \item Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... \& Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. \textit{Journal of Machine Learning Research}, 12, 2825-2830.
    
    \item Pok√©mon TCG Developers. (2025). Pok√©mon TCG API. Recuperado de https://dev.pokemontcg.io/
    
    \item Raschka, S. (2020). \textit{Machine Learning with Python}. Packt Publishing.
    
    \item Scikit-learn Developers. (2023). \textit{Scikit-learn User Guide}. Recuperado de https://scikit-learn.org/stable/user\_guide.html
    
    \item VanderPlas, J. (2016). \textit{Python Data Science Handbook: Essential Tools for Working with Data}. O'Reilly Media.
    
    \item Witten, I. H., Frank, E., Hall, M. A., \& Pal, C. J. (2016). \textit{Data Mining: Practical Machine Learning Tools and Techniques} (4th ed.). Morgan Kaufmann.
    
    \item Zhou, Z. H. (2012). \textit{Ensemble Methods: Foundations and Algorithms}. CRC Press.
\end{enumerate}

\newpage

% GLOSARIO DE T√âRMINOS
\section{Glosario de T√©rminos}

\begin{itemize}
    \item \textbf{Accuracy (Precisi√≥n):} M√©trica que mide la proporci√≥n de predicciones correctas sobre el total de predicciones realizadas.
    
    \item \textbf{Agregados de ataque/habilidad:} Res√∫menes num√©ricos derivados de los atributos de la carta para el modelado, como el conteo y promedios de da√±o.
    
    \item \textbf{API (Application Programming Interface):} Interfaz que permite la comunicaci√≥n entre diferentes aplicaciones de software.
    
    \item \textbf{Aprendizaje supervisado:} Paradigma de Machine Learning donde el modelo aprende a partir de ejemplos con etiqueta conocida (X, y) para predecir en nuevos datos.
    
    \item \textbf{Bagging (Bootstrap Aggregating):} T√©cnica de ensemble que combina m√∫ltiples modelos entrenados en diferentes muestras bootstrap del dataset original.
    
    \item \textbf{Clasificaci√≥n binaria:} Tarea predictiva con dos clases posibles (p. ej., carta 'de alto valor' = 1 vs. 'de valor regular' = 0).
    
    \item \textbf{Clustering:} T√©cnica de aprendizaje no supervisado que agrupa datos similares en clusters o grupos.
    
    \item \textbf{Cross-validation (Validaci√≥n cruzada):} T√©cnica de validaci√≥n que divide el dataset en k subconjuntos para evaluar el rendimiento del modelo.
    
    \item \textbf{Data leakage (Filtraci√≥n de datos):} Situaci√≥n donde informaci√≥n del conjunto de prueba se filtra al conjunto de entrenamiento, causando sobreestimaci√≥n del rendimiento.
    
    \item \textbf{Desbalance de clases:} Situaci√≥n en la que una clase (p. ej., 'de alto valor') es mucho menos frecuente que la otra, afectando el entrenamiento y las m√©tricas del modelo.
    
    \item \textbf{EDA (An√°lisis Exploratorio de Datos):} Proceso inicial para comprender la estructura, la calidad y los patrones de los datos antes del modelado.
    
    \item \textbf{Ensemble methods:} T√©cnicas que combinan m√∫ltiples modelos para mejorar el rendimiento predictivo.
    
    \item \textbf{F1-score:} Media arm√≥nica de precisi√≥n y exhaustividad; balancea la importancia de falsos positivos y falsos negativos.
    
    \item \textbf{Feature engineering (Ingenier√≠a de caracter√≠sticas):} Creaci√≥n y transformaci√≥n de variables para mejorar el rendimiento de un modelo (p. ej., n√∫mero de ataques, da√±o promedio).
    
    \item \textbf{Feature importance (Importancia de caracter√≠sticas):} Medida que indica qu√© tan importante es cada variable para las predicciones del modelo.
    
    \item \textbf{Grid Search:} T√©cnica de optimizaci√≥n de hiperpar√°metros que prueba todas las combinaciones posibles de par√°metros.
    
    \item \textbf{Hiperpar√°metros:} Par√°metros de configuraci√≥n del algoritmo que no se aprenden durante el entrenamiento.
    
    \item \textbf{Imputaci√≥n de valores:} Estrategias para completar valores faltantes (nulos) con reglas o estimaciones.
    
    \item \textbf{Jugabilidad (playability):} Utilidad competitiva de una carta en el metajuego; influye en su demanda y precio.
    
    \item \textbf{K-Means:} Algoritmo de clustering que divide los datos en k clusters minimizando la suma de cuadrados intra-cluster.
    
    \item \textbf{Legalidades (standard/expanded/unlimited):} Formato(s) en los que la carta es jugable; afectan su relevancia en torneos y en el mercado.
    
    \item \textbf{Matriz de confusi√≥n:} Tabla que muestra el rendimiento de un algoritmo de clasificaci√≥n comparando las predicciones con los valores reales.
    
    \item \textbf{M√©todo del codo:} T√©cnica para determinar el n√∫mero √≥ptimo de clusters en algoritmos de clustering.
    
    \item \textbf{Overfitting (Sobreajuste):} Situaci√≥n donde el modelo se ajusta demasiado a los datos de entrenamiento y pierde capacidad de generalizaci√≥n.
    
    \item \textbf{Outlier:} Observaci√≥n extrema que se desv√≠a mucho del resto de los datos; puede sesgar medidas estad√≠sticas y modelos predictivos.
    
    \item \textbf{Percentil (p95):} Valor por encima del cual se ubica el 5\% superior de la distribuci√≥n de precios.
    
    \item \textbf{Precision (Precisi√≥n):} Proporci√≥n de predicciones positivas correctas sobre el total de predicciones positivas.
    
    \item \textbf{Precio de mercado (TCGplayer Market):} Referencia de precio agregada por la plataforma TCGplayer; se usa como una aproximaci√≥n al valor econ√≥mico real.
    
    \item \textbf{PR-AUC:} √Årea bajo la curva Precisi√≥n‚ÄìRecall; √∫til cuando la clase positiva es rara.
    
    \item \textbf{Random Forest:} Algoritmo de ensemble que combina m√∫ltiples √°rboles de decisi√≥n usando bagging y selecci√≥n aleatoria de caracter√≠sticas.
    
    \item \textbf{Rareza (rarity):} Clasificaci√≥n editorial que indica cu√°n com√∫n o escasa es una carta; se correlaciona con su valor potencial.
    
    \item \textbf{Recall (Exhaustividad):} Proporci√≥n de casos positivos correctamente identificados sobre el total de casos positivos reales.
    
    \item \textbf{Regresi√≥n Log√≠stica:} Algoritmo de clasificaci√≥n que utiliza la funci√≥n log√≠stica para modelar la probabilidad de pertenencia a una clase.
    
    \item \textbf{ROC-AUC:} √Årea bajo la curva ROC; mide la capacidad de un modelo para distinguir entre clases a diferentes umbrales.
    
    \item \textbf{Silhouette Score:} M√©trica que eval√∫a la calidad del clustering midiendo qu√© tan similar es un objeto a su propio cluster comparado con otros clusters.
    
    \item \textbf{StandardScaler:} T√©cnica de normalizaci√≥n que transforma los datos para que tengan media 0 y desviaci√≥n est√°ndar 1.
    
    \item \textbf{Variable objetivo (target):} Columna que se busca predecir; en este trabajo, la etiqueta de 'carta de alto valor' definida por el percentil 95 del precio de mercado.
    
    \item \textbf{Variance Threshold:} T√©cnica de selecci√≥n de caracter√≠sticas que elimina variables con varianza menor a un umbral especificado.
\end{itemize}

\newpage

% AP√âNDICES
\section{Ap√©ndices}

\subsection{Ap√©ndice A: C√≥digo de Preprocesamiento}

El c√≥digo completo de preprocesamiento se encuentra disponible en los notebooks:
\begin{itemize}
    \item \texttt{Primer\_Corte\_ML\_Pokemon\_TCG\_Final.ipynb}
    \item \texttt{Segundo\_Corte\_ML\_Pokemon\_TCG.ipynb}
    \item \texttt{fetch\_ptcg\_by\_set\_full\_csv.py}
    \item \texttt{01\_preprocess\_ptcg.py}
\end{itemize}

\subsection{Ap√©ndice B: Gr√°ficas y Visualizaciones}

Las siguientes gr√°ficas fueron capturadas e integradas en el documento:

\textbf{Del Primer Corte:}
\begin{enumerate}
    \item Distribuci√≥n de la variable objetivo (carta\_cara) - Figura \ref{fig:distribucion_objetivo}
    \item An√°lisis de precios por rareza - Figura \ref{fig:precios_rareza}
    \item Tabla de an√°lisis de rareza - Figura \ref{fig:tabla_rareza}
    \item An√°lisis de variable objetivo - Figura \ref{fig:analisis_objetivo}
\end{enumerate}

\textbf{Del Segundo Corte:}
\begin{enumerate}
    \item Variables categ√≥ricas - Figura \ref{fig:variables_categoricas}
    \item Matriz de correlaciones - Figura \ref{fig:correlaciones}
    \item Matriz de confusi√≥n Regresi√≥n Log√≠stica - Figura \ref{fig:confusion_lr}
    \item Matriz de confusi√≥n Random Forest - Figura \ref{fig:confusion_rf}
    \item M√©todo del codo K-Means - Figura \ref{fig:metodo_codo}
    \item Comparaci√≥n de modelos - Figura \ref{fig:comparacion_modelos}
\end{enumerate}

\textbf{Configuraci√≥n del Proyecto:}
\begin{enumerate}
    \item Configuraci√≥n del entorno virtual - Figura \ref{fig:configuracion_entorno}
    \item Instalaci√≥n de dependencias - Figura \ref{fig:instalacion_dependencias}
    \item API Key de Pok√©mon TCG - Figura \ref{fig:api_key_pokemon}
    \item Variables de entorno - Figura \ref{fig:configuracion_env}
\end{enumerate}

\subsection{Ap√©ndice C: Metadatos de Modelos}

Los modelos entrenados se guardaron con metadatos completos en la carpeta \texttt{modelos\_entrenados/}:

\textbf{Estructura de archivos:}
\begin{itemize}
    \item \texttt{regresi√≥n\_log√≠stica/}
    \begin{itemize}
        \item \texttt{regresi√≥n\_log√≠stica\_model.pkl} - Modelo entrenado
        \item \texttt{regresi√≥n\_log√≠stica\_scaler.pkl} - Scaler utilizado
        \item \texttt{metadata.json} - Metadatos del modelo
    \end{itemize}
    \item \texttt{random\_forest/}
    \begin{itemize}
        \item \texttt{random\_forest\_model.pkl} - Modelo entrenado
        \item \texttt{metadata.json} - Metadatos del modelo
    \end{itemize}
    \item \texttt{k-means/}
    \begin{itemize}
        \item \texttt{k-means\_model.pkl} - Modelo entrenado
        \item \texttt{metadata.json} - Metadatos del modelo
    \end{itemize}
\end{itemize}

\textbf{Contenido de metadatos:}
\begin{itemize}
    \item Fecha de entrenamiento
    \item Tipo de modelo
    \item M√©tricas de rendimiento
    \item Features utilizadas
    \item Tama√±o del archivo
    \item Par√°metros del modelo
    \item Versi√≥n de scikit-learn
\end{itemize}

\subsection{Ap√©ndice D: Estructura del Proyecto}

\textbf{Archivos principales:}
\begin{itemize}
    \item \texttt{Informe\_Proyecto\_Final\_ML\_APA.tex} - Documento principal
    \item \texttt{Primer\_Corte\_ML\_Pokemon\_TCG\_Final.ipynb} - Notebook primer corte
    \item \texttt{Segundo\_Corte\_ML\_Pokemon\_TCG.ipynb} - Notebook segundo corte
    \item \texttt{fetch\_ptcg\_by\_set\_full\_csv.py} - Script descarga de datos
    \item \texttt{01\_preprocess\_ptcg.py} - Script preprocesamiento
\end{itemize}

\textbf{Carpetas de datos:}
\begin{itemize}
    \item \texttt{ptcg\_data/} - Datos originales y procesados
    \item \texttt{imagenes/} - Gr√°ficas y visualizaciones
    \item \texttt{modelos\_entrenados/} - Modelos guardados
    \item \texttt{archivos\_antiguos/} - Archivos de versiones anteriores
\end{itemize}

\subsection{Ap√©ndice E: Configuraci√≥n del Entorno}

\textbf{Especificaciones t√©cnicas:}
\begin{itemize}
    \item Python 3.11.9
    \item Sistema operativo: Windows 10
    \item Editor: Visual Studio Code
    \item Entorno virtual: .venv
\end{itemize}

\textbf{Librer√≠as principales:}
\begin{itemize}
    \item pandas 2.3.2 - Manipulaci√≥n de datos
    \item scikit-learn - Algoritmos de ML
    \item numpy - Computaci√≥n num√©rica
    \item matplotlib/seaborn - Visualizaciones
    \item requests - Descarga de API
    \item pyarrow - Formato Parquet
    \item tqdm - Barras de progreso
    \item python-dotenv - Variables de entorno
\end{itemize}

\end{document}
